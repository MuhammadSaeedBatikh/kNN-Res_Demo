{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# !pip install geomloss\n",
    "from geomloss import SamplesLoss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from typing import List, Tuple, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load data\n",
    "ref_data = pd.read_csv('data/ref_2_bunnies.csv', sep=',', decimal='.').to_numpy()\n",
    "source = pd.read_csv('data/source_2_bunnies_def_from_center.csv', sep=',', decimal='.').to_numpy()\n",
    "ref_data = torch.tensor(ref_data, dtype=torch.float32)\n",
    "source = torch.tensor(source, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "text/plain": "([], [])"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.scatter(*ref_data.T, s=5, label='ref',  c=[0, 0.4470, 0.7410])\n",
    "# plt.scatter(*source.T, s=5, label='target', c=[0.8500, 0.3250,    0.0980])\n",
    "plt.scatter(ref_data[:, 0], ref_data[:, 1], s=5, c=[0, 0.4470,  0.7410], label='ref')\n",
    "plt.scatter(source[:, 0], source[:, 1], s=5, c=[0.4940,    0.1840,    0.5560], label='aligned')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "#plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def jaccobian_finite_diff(G: nn.Module,\n",
    "                          z: torch.Tensor,\n",
    "                          epsilon: float,\n",
    "                          G_z: torch.Tensor = None,\n",
    "                          ret_iso_jac_and_I: bool = True):\n",
    "    \"\"\"\n",
    "    :param G: function/network to compute the jaccobian Penalty for.\n",
    "    :param z: input to G that the Hessian Penalty is taken w.r.t.\n",
    "    :param epsilon: step size for finite difference.\n",
    "    :param G_z: precomputed original input.\n",
    "    :param ret_iso_jac_and_I: if `True`, computes batch J^T @ j and returns it alongside identity I with appropriate shape,\n",
    "     else returns batch Jacobian.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, d = z.shape\n",
    "    if G_z is None:\n",
    "        G_z = G(z)\n",
    "    # Gz_rep is [batch_size * d, d]\n",
    "    Gz_rep = G_z.view(-1, 1, d).repeat(1, d, 1).view(-1, d)\n",
    "    I = torch.eye(d, device=z.device).repeat(batch_size, 1, 1)\n",
    "    surg = (epsilon * I + z.unsqueeze(-1)).transpose(2, 1).reshape(-1, d)\n",
    "    out = G(surg)\n",
    "    jac = ((out - Gz_rep) / epsilon).reshape(-1, d, d)\n",
    "    if ret_iso_jac_and_I:\n",
    "        return torch.bmm(jac, jac), I\n",
    "    else:\n",
    "        return jac"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class WarpKnn(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=2,\n",
    "                 hidden_dim=20,\n",
    "                 w_init_delta=0.02,\n",
    "                 out_dim=None,\n",
    "                 alpha=0.05,\n",
    "                 init_last_layer=False,\n",
    "                 max_batch_at_once=2500,\n",
    "                 device='cpu'):\n",
    "        \"\"\"\n",
    "          :param input_dim:\n",
    "          :param hidden_dim:\n",
    "          :param w_init_delta:\n",
    "          :param out_dim:\n",
    "          :param alpha:\n",
    "          :param init_last_layer:\n",
    "          :param max_batch_at_once:\n",
    "          :param device:\n",
    "        \"\"\"\n",
    "\n",
    "        super(WarpKnn, self).__init__()\n",
    "        self.w_init_delta = w_init_delta\n",
    "        self.alpha = alpha\n",
    "        self.input_dim = input_dim\n",
    "        self.out_dim = out_dim if out_dim is not None else input_dim\n",
    "        self.init_last_layer = init_last_layer\n",
    "        self.max_batch_at_once = max_batch_at_once\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(self.alpha),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(self.alpha),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(self.alpha),\n",
    "            nn.Linear(hidden_dim, self.out_dim),\n",
    "        ).to(device)\n",
    "        parameters = list(self.block.parameters())\n",
    "        for j, p in enumerate(parameters[-2:]):\n",
    "            print(p.data.shape)\n",
    "            if not self.init_last_layer:\n",
    "                p.data = self.w_init_delta * torch.rand_like(p.data, requires_grad=True)\n",
    "            else:\n",
    "                p.data = self.w_init_delta * torch.rand_like(p.data, requires_grad=True)\n",
    "\n",
    "    def forward(self, x, large=True):\n",
    "        if large and x.shape[0] > self.max_batch_at_once:\n",
    "            return self._calc_large_batch(x)\n",
    "        else:\n",
    "            t = self.block(x)\n",
    "            if self.out_dim == self.input_dim:\n",
    "                r = t + x\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f'Mismatched output and input dimensions:'\n",
    "                    f' out_dim{self.out_dim} != input_dim{self.input_dim}'\n",
    "                )\n",
    "            #     r = t + torch.pca_lowrank(x, self.out_dim)[0]\n",
    "            return r, t\n",
    "\n",
    "    def _calc_large_batch(self, x):\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data_size = x.shape[0]\n",
    "        outs = []\n",
    "        ts = []\n",
    "        for start in range(0, data_size, self.max_batch_at_once):\n",
    "            end = start + self.max_batch_at_once\n",
    "            batch = x[start:end]\n",
    "            out, t = self(batch)\n",
    "            outs += [out]\n",
    "            ts += [t]\n",
    "        r = torch.concat(outs, 0)\n",
    "        t = torch.concat(ts, 0)\n",
    "        return r, t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 50])\n",
      "torch.Size([2])\n",
      "0 || alignment_loss: 0.011651  || reg:0.000500\n",
      "5 || alignment_loss: 0.008337  || reg:0.000498\n",
      "10 || alignment_loss: 0.004687  || reg:0.000361\n",
      "15 || alignment_loss: 0.002502  || reg:0.000319\n",
      "20 || alignment_loss: 0.003402  || reg:0.000345\n",
      "25 || alignment_loss: 0.002028  || reg:0.000372\n",
      "30 || alignment_loss: 0.001670  || reg:0.000361\n",
      "35 || alignment_loss: 0.001795  || reg:0.000374\n",
      "40 || alignment_loss: 0.001721  || reg:0.000363\n",
      "45 || alignment_loss: 0.001600  || reg:0.000353\n",
      "50 || alignment_loss: 0.001516  || reg:0.000341\n",
      "55 || alignment_loss: 0.001411  || reg:0.000332\n",
      "60 || alignment_loss: 0.001261  || reg:0.000316\n",
      "65 || alignment_loss: 0.001193  || reg:0.000301\n",
      "70 || alignment_loss: 0.001022  || reg:0.000282\n",
      "75 || alignment_loss: 0.000798  || reg:0.000242\n",
      "80 || alignment_loss: 0.000582  || reg:0.000208\n",
      "85 || alignment_loss: 0.000571  || reg:0.000155\n",
      "90 || alignment_loss: 0.000182  || reg:0.000138\n",
      "95 || alignment_loss: 0.000213  || reg:0.000118\n",
      "100 || alignment_loss: 0.000181  || reg:0.000101\n",
      "200 || alignment_loss: 0.000018  || reg:0.000023\n",
      "300 || alignment_loss: 0.000001  || reg:0.000013\n",
      "400 || alignment_loss: 0.000001  || reg:0.000008\n",
      "500 || alignment_loss: 0.000001  || reg:0.000005\n",
      "600 || alignment_loss: 0.000000  || reg:0.000004\n",
      "700 || alignment_loss: 0.000000  || reg:0.000004\n",
      "800 || alignment_loss: 0.000000  || reg:0.000004\n",
      "900 || alignment_loss: 0.000000  || reg:0.000004\n",
      "1000 || alignment_loss: 0.000000  || reg:0.000003\n",
      "1100 || alignment_loss: 0.000000  || reg:0.000003\n",
      "1200 || alignment_loss: 0.000000  || reg:0.000003\n",
      "1300 || alignment_loss: 0.000000  || reg:0.000003\n",
      "1400 || alignment_loss: 0.000000  || reg:0.000003\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "lr = 1e-2\n",
    "batch_size = source.shape[0]  #full batch\n",
    "iterations = 1500\n",
    "hidden = 50\n",
    "sigma = 0.05\n",
    "eps = 5e-3\n",
    "lam = 5e-3\n",
    "\n",
    "# shuffling data to make sure correspondence is lost.\n",
    "idx = torch.randperm(source.shape[0])\n",
    "source_data = source[idx]\n",
    "\n",
    "exp_dict = {}\n",
    "use_sinkhorn_loss = True\n",
    "use_jac_penality = True\n",
    "\n",
    "loss_align_hist = []\n",
    "loss_reg_hist = []\n",
    "\n",
    "warpknn_model = WarpKnn(input_dim=ref_data.shape[-1],\n",
    "                        hidden_dim=hidden,\n",
    "                        w_init_delta=0.015,\n",
    "                        alpha=0.05,\n",
    "                        init_last_layer=True\n",
    "                        ).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(list(warpknn_model.parameters()), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min',\n",
    "                                                       factor=0.7,\n",
    "                                                       patience=50,\n",
    "                                                       threshold=1e-4,\n",
    "                                                       min_lr=5e-5,\n",
    "                                                       threshold_mode='rel')\n",
    "if use_sinkhorn_loss:\n",
    "    alignment_loss_fn = SamplesLoss(loss='sinkhorn',\n",
    "                                    blur=sigma,\n",
    "                                    p=2,\n",
    "                                    )\n",
    "else:\n",
    "    alignment_loss_fn = SamplesLoss(loss='gaussian', blur=sigma)\n",
    "\n",
    "# using full batch for this example\n",
    "batch_X, batch_Y = ref_data, source_data\n",
    "batch_X = batch_X.to(device)\n",
    "batch_Y = batch_Y.to(device)\n",
    "for idx in range(iterations):\n",
    "    # batch_X, batch_Y = subsample(ref_data, batch_size)[0], \\\n",
    "    #                subsample(target_data, batch_size)[0]\n",
    "\n",
    "    out, t = warpknn_model(batch_Y, large=False)\n",
    "    alignment_loss = alignment_loss_fn(out, batch_X)\n",
    "    if alignment_loss < 1e-8:\n",
    "        break\n",
    "    if use_jac_penality:\n",
    "        jac_T_jac, I = jaccobian_finite_diff(warpknn_model.block,\n",
    "                                             batch_Y,\n",
    "                                             G_z=t,\n",
    "                                             epsilon=eps,\n",
    "                                             ret_iso_jac_and_I=True)\n",
    "        reg_loss = lam * torch.abs(jac_T_jac - I).mean([1, 2]).mean()\n",
    "        loss = alignment_loss + reg_loss\n",
    "    else:\n",
    "        reg_loss = torch.tensor(0.0)\n",
    "        loss = alignment_loss\n",
    "    optim.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optim.step()\n",
    "    scheduler.step(alignment_loss)\n",
    "    every = 5 if idx < 100 else 100\n",
    "    if idx % every == 0:\n",
    "        loss_align_hist += [alignment_loss.detach().item()]\n",
    "        loss_reg_hist += [reg_loss.detach().item()]\n",
    "        print(f'{idx} || alignment_loss: {alignment_loss:3f}  || reg:{reg_loss :3f}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x20737fe05b0>]"
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(loss_align_hist)\n",
    "plt.figure()\n",
    "plt.plot(loss_reg_hist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n",
      "(400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x20750bec370>"
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import helper\n",
    "reload(helper)\n",
    "from helper import ndmeshgrid, plot_grid_warp\n",
    "%matplotlib qt\n",
    "plt.rcParams['axes.facecolor']=[0.95, 0.95, 0.95]\n",
    "warpknn_model.train(False)\n",
    "warpknn_model.to('cpu')\n",
    "ref_data = ref_data.to('cpu')\n",
    "source_data = source_data.to('cpu')\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "grid_xy_min = source_data.min(0)[0].detach().numpy()-.1\n",
    "grid_xy_max = source_data.max(0)[0].detach().numpy()+.1\n",
    "mesh_test = ndmeshgrid(dim=source_data.shape[-1],\n",
    "                       step=20,\n",
    "                       mi=grid_xy_min,\n",
    "                       mx=grid_xy_max,\n",
    "                       )\n",
    "print(mesh_test.shape)\n",
    "Y_trans_mesh = warpknn_model(torch.as_tensor(mesh_test, dtype=torch.float, ))[0].detach().cpu().numpy()\n",
    "plot_grid_warp(mesh_test, Y_trans_mesh, linewidth=2, s1=5, s2=5, c1=[0, 0.4470,  0.7410], c2=[0.8500, 0.3250, 0.0980], alpha=0.125)\n",
    "#plt.suptitle(f'Estimated Transformation')\n",
    "Y_trans = warpknn_model(source_data)[0].detach().cpu().numpy()\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plot_grid_warp(source_data, Y_trans, linewidth=2, s1=5, s2=5, c1=[0, 0.4470,  0.7410], c2=[0.8500, 0.3250, 0.0980], alpha=0.125,\n",
    "               label1='target', label2='aligned')\n",
    "#plt.legend()\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.scatter(ref_data[:, 0], ref_data[:, 1], s=5, c=[0, 0.4470,  0.7410], label='ref')\n",
    "plt.scatter(Y_trans[:, 0], Y_trans[:, 1], s=5, c=[0.8500, 0.3250, 0.0980], label='aligned')\n",
    "#plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "reg_iden = 'jac' if use_jac_penality else 'no_reg'\n",
    "np.savetxt(f'results/bunny/mesh_input.csv', mesh_test, delimiter=',')\n",
    "np.savetxt(f'results/bunny/mesh_transformed_{reg_iden}.csv', Y_trans_mesh, delimiter=',')\n",
    "np.savetxt(f'results/bunny/transformed_source_{reg_iden}.csv', Y_trans, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
